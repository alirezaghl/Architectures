{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkjhyMkAZ+NMfYdda0R9Jy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alirezaghl/Architectures/blob/main/Unet_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a simple implementation of Unet based on the original paper."
      ],
      "metadata": {
        "id": "pDLzqVTUzZqk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "18A96V3hQXYK"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Helper function that is consist of two convolution operation followed by a relu activation function, we are gonna use this function throughout the architecture. Both are 2D convolutions with the kernel size of 2 and without padding as mentioned in the paper."
      ],
      "metadata": {
        "id": "IB4dRpjQzteG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def double_convolution(in_ch, out_ch):\n",
        "  output = nn.Sequential(\n",
        "      nn.Conv2d(in_ch, out_ch, kernel_size=3),\n",
        "      nn.ReLU(inplace=True),\n",
        "      nn.Conv2d(out_ch, out_ch, kernel_size=3),\n",
        "      nn.ReLU(inplace=True)\n",
        "      )\n",
        "  return output\n"
      ],
      "metadata": {
        "id": "gygjsDeGW6Df"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s make sure this implementation works:\n"
      ],
      "metadata": {
        "id": "jjh4c-EW0aTs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 1, 572, 572)\n",
        "y = double_convolution(1,64)\n",
        "z = y(x)\n",
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eoIksWSheikT",
        "outputId": "349a5873-034a-4541-9300-e95178568e3c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 568, 568])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first part is the contractive path wich takes channel numbers from 1 to 1024. For the first part, we perform the MaxPooling operation to the outputs of double convolution function. As mentioned in the paper the kernel size and number of strides for MaxPooling operation are both 2. the final feature map of the contractive path is of size 1024x28x28.\\\n",
        "The second part is the expansive path is just like the previous one but this time instead of using MaxPooling, we are going to use up_convolution operation followd by concatenation with correspondingly feature map from the contractive path, but there is one problem !\\\n",
        "The outputs of the contracting part must be cropped so that their dimensions match those of the expansive part. The final feature map is 64x388x388, followed by another convolution that reduces the number of channels from 64 to two."
      ],
      "metadata": {
        "id": "lTY9mleC1Wsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Unet, self).__init__()\n",
        "\n",
        "    self.conv1 = double_convolution(1,64)\n",
        "    self.conv2 = double_convolution(64, 128)\n",
        "    self.conv3 = double_convolution(128, 256)\n",
        "    self.conv4 = double_convolution(256, 512)\n",
        "    self.conv5 = double_convolution(512, 1024)\n",
        "    self.Maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "    self.deconv1 = nn.ConvTranspose2d(kernel_size=2, stride=2, in_channels=1024, out_channels=512)\n",
        "    self.deconv2 = nn.ConvTranspose2d(kernel_size=2, stride=2, in_channels=512, out_channels=256)\n",
        "    self.deconv3 = nn.ConvTranspose2d(kernel_size=2, stride=2, in_channels=256, out_channels=128)\n",
        "    self.deconv4 = nn.ConvTranspose2d(kernel_size=2, stride=2, in_channels=128, out_channels=64)\n",
        "    self.conv6 = double_convolution(1024,512)\n",
        "    self.conv7 = double_convolution(512, 256)\n",
        "    self.conv8 = double_convolution(256, 128)\n",
        "    self.conv9 = double_convolution(128, 64)\n",
        "    self.conv10 = nn.Conv2d(64, 2, kernel_size=1)\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self, image):\n",
        "    x1 = self.Maxpool(self.conv1(image))\n",
        "    x1_output = self.conv1(image)[:, :, :392, :392]\n",
        "    x2 = self.Maxpool(self.conv2(x1))\n",
        "    x2_output = self.conv2(x1)[:, :, :200, :200]\n",
        "    x3 = self.Maxpool(self.conv3(x2))\n",
        "    x3_output = self.conv3(x2)[:, :, :104, :104]\n",
        "    x4 = self.Maxpool(self.conv4(x3))\n",
        "    x4_output = self.conv4(x3)[:, :, :56, :56]\n",
        "    x5 = self.conv5(x4)\n",
        "    x6 = self.deconv1(x5)\n",
        "    x6_cat = self.conv6(torch.cat([x6,x4_output], 1))\n",
        "    x7 = self.deconv2(x6_cat)\n",
        "    x7_cat = self.conv7(torch.cat([x7, x3_output], 1))\n",
        "    x8 = self.deconv3(x7_cat)\n",
        "    x8_cat = self.conv8(torch.cat([x8, x2_output], 1))\n",
        "    x9 = self.deconv4(x8_cat)\n",
        "    x9_cat = self.conv9(torch.cat([x9, x1_output], 1))\n",
        "    out = self.conv10(x9_cat)\n",
        "\n",
        "    return out.shape"
      ],
      "metadata": {
        "id": "3Q-CmaM1Ri7y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s make sure this implementation works:"
      ],
      "metadata": {
        "id": "YhOARHyr8jXV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(1, 1, 572, 572)\n",
        "y = Unet()\n",
        "z = y(x)\n",
        "z"
      ],
      "metadata": {
        "id": "2uc-i9G4aUi9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "010afa4d-1626-4c10-b61e-24098be35126"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 2, 388, 388])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    }
  ]
}